# 每日复盘与总结

## 2023.10.28

### 算法

一开始回顾了快排和归并排序的算法实现。快排和归并都用到了递归，也就是分治的思想
快排选取的比较值是随机选取的，在这个算法中选的是$q[l+r>>1]$处的值
归并是划分成两个区间后，对这两个区间中的值进行排序，递归地对全局进行排序

**特别注意的是循环条件以及等号是否能够选取。**

$DFS$和$BFS$都是搜索算法，区别是$BFS$能够找到最优$^{[1]}$，如果只是求解而不考虑最优时可以用$BFS$.

树与图的存储一般使用邻接表进行存储的，但是一般用数组模拟邻接表。

输入数据量为$10^6$时，考虑`scanf`，否则`cin`的误差可忽略。

### 语音深度学习

根据[语音信号处理的深度学习入门](https://zhuanlan.zhihu.com/p/386467252)，再次梳理了语音深度学习的基础知识部分，存放在*E:\HQU\科研\语音伪造检测\notes.md*

关键是成功运行了一个获取Mel谱的代码，总结一下步骤就是
$$
头尾静音消除→预加重→STFT→获取幅度谱→获取Mel谱
$$
学习了李沐的深度学习中第六章 卷积神经网络的相关内容，浅浅说一下自己的思考：

之前的DNN在CNN没有出现之前，一直都是使用MLP进行数据处理，这对于早期的深度学习而言并没有太大问题，但会遇到以下两个方面的挑战：$(1)$倘若数据量不断增加时，MLP的参数便会不断增长.$(2)$对于图像类数据而言，MLP的参数同样会日益膨胀.尤其是对于问题$(2)$而言，当时的人们思考是否能够精简模型的学习参数，对于图像而言，还要考虑到最重要的两个性质:$(1)$平移不变性$(2)$局部性，因此卷积运算$^{[2]}$便巧妙地与神经网络结合起来。



$————————————————————————————————————————————————————————$

$[1]$ $BFS$找到最优仅适用于权重相同的情况，权重不同考虑最短路如$Dijkstra$，同时如果没有环路，也可以使用$DP$。

$[2]$ 卷积运算常被定义为:$(f*g)(t)= \int_{-\infty}^{+\infty}f(x)g(t-x)dt$.在CNN中，卷积运算与该式中所写的有着微妙的不同，但从本质上来讲是一回事。此处不展开赘述，请参考b站视频或其它资料.
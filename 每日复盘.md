# 每日复盘与总结

## 2023.10.28

### 算法

一开始回顾了快排和归并排序的算法实现。快排和归并都用到了递归，也就是分治的思想
快排选取的比较值是随机选取的，在这个算法中选的是$q[l+r>>1]$处的值
归并是划分成两个区间后，对这两个区间中的值进行排序，递归地对全局进行排序

**特别注意的是循环条件以及等号是否能够选取。**

$DFS$和$BFS$都是搜索算法，区别是$BFS$能够找到最优$^{[1]}$，如果只是求解而不考虑最优时可以用$BFS$.

树与图的存储一般使用邻接表进行存储的，但是一般用数组模拟邻接表。

输入数据量为$10^6$时，考虑`scanf`，否则`cin`的误差可忽略。

### 语音深度学习

根据[语音信号处理的深度学习入门](https://zhuanlan.zhihu.com/p/386467252)，再次梳理了语音深度学习的基础知识部分，存放在*E:\HQU\科研\语音伪造检测\notes.md*

关键是成功运行了一个获取Mel谱的代码，总结一下步骤就是
$$
头尾静音消除→预加重→STFT→获取幅度谱→获取Mel谱
$$
学习了李沐的深度学习中第六章 卷积神经网络的相关内容，浅浅说一下自己的思考：

之前的DNN在CNN没有出现之前，一直都是使用MLP进行数据处理，这对于早期的深度学习而言并没有太大问题，但会遇到以下两个方面的挑战：$(1)$倘若数据量不断增加时，MLP的参数便会不断增长.$(2)$对于图像类数据而言，MLP的参数同样会日益膨胀.尤其是对于问题$(2)$而言，当时的人们思考是否能够精简模型的学习参数，对于图像而言，还要考虑到最重要的两个性质:$(1)$平移不变性$(2)$局部性，因此卷积运算$^{[2]}$便巧妙地与神经网络结合起来。



$————————————————————————————————————————————————————————$

$[1]$ $BFS$找到最优仅适用于权重相同的情况，权重不同考虑最短路如$Dijkstra$，同时如果没有环路，也可以使用$DP$。

$[2]$ 卷积运算常被定义为:$(f*g)(t)= \int_{-\infty}^{+\infty}f(x)g(t-x)dt$.在CNN中，卷积运算与该式中所写的有着微妙的不同，但从本质上来讲是一回事。此处不展开赘述，请参考b站视频或其它资料.



## 2023.10.31

### Pytorch学习

**以后数据集可以去Kaggle上找。。下载完了之后再放到data文件夹里。。**



可以查询[TORCH.UTILS.DATA](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset)来查看相关API

- `torch.utils.data.Dataset`	[link](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset)
  - 简单来说是用来读取数据集的类
  - 支持自定义数据集，不过需要重写`__init__(self,...)`,`__len__(self)`,`__getitem__(self,idx)`方法
  - `__getitem__()`的魔法函数使得实例化的对象支持下标访问

- ``torch.utils.data.DataLoader`    [link](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)
  - 用来加载数据集，并对数据集进行一系列操作
  - 实例化的对象是可迭代的，因此可以用于训练，其余相关参数详见link
- `torch.nn`    link







### 论文阅读

#### A study on data augmentation in voice anti-spoofing

Ariel Cohen ∗,**, Inbal Rimon**, Eran Aflalo, Haim H. Permuter

Speech Communication

##### 摘要部分：

在本文中，我们对数据增强技术如何改进合成或欺骗的音频检测进行了深入的研究。具体地说，我们提出了处理**信道变化、不同的音频压缩、不同的带宽、不可见的欺骗攻击**的方法。这些挑战，都被证明显著降低基于音频的系统和反欺骗系统的性能。我们的研究结果是基于ASVspoof 2021挑战，在逻辑访问（LA）和深度伪造（DF）类别中。我们的研究是**以数据为中心**的，这意味着模型是固定的，我们通过操纵数据显著地改善了结果。我们介绍了两种形式的数据增强-测向部分的压缩增强，以及LA部分的压缩和信道增强。此外，还介绍了一种新型的在线数据增强方法，即规格平均。该方法包括将音频特征的**平均值**掩蔽，以提高泛化性。我们最好的单一系统和融合方案在DF类别中都达到了最先进的性能，EER分别为15.46%和14.27%。我们对LA任务的最佳系统将最佳基线EER降低了50%，最小t-DCF降低了16%。我们处理来自各种分布的欺骗数据的技术可以被复制，并可以帮助反欺骗和基于语音的系统增强他们的结果。

Keywords：ASVspoof 2021	Audio data augmentation	Data-centric AI	SpecAugment 	Voice anti spoofing	Voice deep fake

##### 遇到的问题

语音伪造检测所面临的问题：

1. **压缩(Compression)**	有损压缩可能会降低ASV的性能
2. **信道效应(Channel effects)**	通过信道传输音频文件所遇到的如丢包、噪声可能会对ASV造成影响
3. **频带差异与滤波(Bandwidth differences and filtering)**	对于不同带宽的编解码器，可能会造成高频信息的丢失，会可能包含伪造检测的关键信息
4. **未见攻击(Unseen spoof attacks)**	对于未知的攻击，ASV的处理性能有所下降

##### 以数据为中心

在这种方法中，模型是固定的，并在数据集中不断地进行更改/改进，以使结果最大化，本文即采用这种方法，采取一系列数据增强以及特征设计的策略对数据加以处理。

##### 动机

1.2.1.2中提到的问题深刻的影响到了ASV系统的性能，激发了相关工作。





##### 疑惑

LFCC、对数谱争取自己实现一下

预加重

什么是receptive field

consecutive frequency bins or coeddicients?

## 2023.11.02

### Pytorch学习

可以查询[TORCH.UTILS.DATA](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset)来查看相关API

- `torch.utils.data.Dataset`	[link](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset)
  - 简单来说是用来读取数据集的类
  - 支持自定义数据集，不过需要重写`__init__(self,...)`,`__len__(self)`,`__getitem__(self,idx)`方法
  - `__getitem__()`的魔法函数使得实例化的对象支持下标访问

- ``torch.utils.data.DataLoader`    [link](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)
  - 用来加载数据集，并对数据集进行一系列操作
  - 实例化的对象是可迭代的，因此可以用于训练，其余相关参数详见link
- `torch.nn.Module`    [link](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module)
  - 用来构建神经网络模型，**是所有神经网络单元（neural network modules）的基类**，同时在`__call__(self,*input,**kwargs)`方法中，调用了`forward(self,input)`函数
  - 因此基于`nn.Module`子类的实例，比如`nn.Linear()`的实例，在写法上类似于函数的写法，可以接收一个参数，比如`m=nn.Linear(20,30)  output=m(input)`，但实际上这个是调用的`__call__(input)`方法，再来调用`forward(input)`函数.
  - 所以在自定义神经网络时，只需要重写`__init__(self)`方法和`forward(self,input)`方法即可。

- `torch.nn.Sequential(*args:Module)`    [link](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential)
  - 用来当作网络层的便捷写法

## 2023.11.04

- 阅读昨天那篇Knowledge Amalgamation的论文,结合之前读的《How to read a paper》文章中所提到的方法
- 《动手学深度学习》 把第七章提到的几个卷积神经网络了解一下，最好放到GPU上去跑一下
- 学习一下前一篇论文中所提到的 SENet神经网络，看一下之前论文的reference里的文章，多读论文
- 算法如果晚上有时间的话，可以练几道。

### 论文《Generalized Voice Spoofing Detection via Integral Knowledge Amalgamation》

#### 摘要

遇到问题：大多数的伪造检测面对的是特定的伪造方法（合成、重放），但真实场景下对于这两种攻击是未知的。

解决方法：

- 本文选择基于整体知识融合(Integral Knowledge Amalgamation)的策略进行识别。
- 主要分为特征融合和结构融合，为了提高泛化性，这两种是分开训练的
  - 特征融合采用teacher model
  - 结构融合采用对抗学习(adversarial learning)
- 采用feature matching loss作为损失函数，对合成攻击和重放攻击加以区分



#### I. Introduction

- 背景
  - ·ASV系统的安全性受到了TTS VC replay的挑战
- 问题
  - 之前的LA与PA都是分开训练的，但实际情况是这两种攻击事先是未知的。
- 现有缺陷
  - 模型复杂，推理时间长
  - 泛化能力差
  - 

#### II. Related Work

[]

#### III. Method

#### IV. Experiments

#### V. Conclusion



- 模型的缺点
  - 在知识合并的过程中，LA语音和PA语音的真实样本并没有明确地对齐。

---

#### 疑惑



- **Q:**[7]中提到了LFCC，我只知道这是一个前端特征提取的方法，这究竟做什么的？

**A：**需要先了解什么是MFCC，好像了解了前端特征提取之后就已经够了，关键是要将代码实现。



- [13,14,15]中都是基于**ResNet**来做的，本文也是基于**ResNet**做的，因此要清楚其原理，并且要实现一下。

ResNet的原理可以看知乎这篇文章[《你必须要知道CNN模型：ResNet》](https://zhuanlan.zhihu.com/p/31852747)，ChatGpt给出的解释是：

> ResNet（Residual Network）是一种深度卷积神经网络（CNN）架构，它的核心思想是引入了残差学习，旨在解决深度神经网络训练中的梯度消失和梯度爆炸问题。ResNet的核心在于它的建模方式和层间跳跃连接。
>
> 以下是ResNet的核心思想和组成部分的解释：
>
> 1. **残差学习：** 在传统的深度神经网络中，层与层之间的映射被表示为恒等映射，即网络的每一层都试图学习将输入映射到输出的完美映射。这在训练非常深的网络时会导致梯度消失问题，因为每个层都需要学会逼近一个恒等映射，这对于很深的网络来说非常困难。
> 2. **残差块：** ResNet引入了残差块（Residual Block），这是网络的基本组成单元。在残差块中，每个块不再尝试学习完美映射，而是学习一个残差（residual），即输入与目标输出之间的差异。这使得网络更容易学习，因为它只需要学会微调输入，而不是学会从头开始重建输出。
> 3. **跳跃连接：** 残差块中的重要部分是跳跃连接或快捷连接，它允许将输入直接添加到块的输出。这样，残差块可以将输入信息保留并传递给下一层，从而解决了梯度消失问题。跳跃连接还有助于减小模型的复杂度，因为它允许网络继续学习恒等映射。
> 4. **深度网络：** ResNet的架构允许构建非常深的网络，因为梯度能够更容易地在网络中传播。因此，ResNet通常以数十、甚至上百层的深度来构建网络，这在传统的深度神经网络中会导致问题的情况下是非常有效的。
>
> 总之，ResNet的核心思想是使用残差学习和跳跃连接来构建深层卷积神经网络，以允许网络更容易地训练和学习复杂的特征表示。这一思想的引入使得深度神经网络在图像分类、目标检测、语义分割等计算机视觉任务中取得了显著的突破，成为深度学习中的重要里程碑。



- [29-35]是关于Knowledge Distillation和Knowledge Amalgamation的，可以看一下相关介绍。



- [37,38]是关于Feature matching loss的，看一下相关介绍。
- 

## 2023.11.07

希望今天能够读完4号的那篇论文

找到一篇[论文粗读攻略](https://github.com/CS-BAOYAN/CSBasicKnowledge/blob/main/%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB%E6%94%BB%E7%95%A5.md)

了解一下Inception和VGG的相关思想

了解一下图神经网络相关

看了一些SENet的知识，其中讲的比较好的是Youtube上的  [Squeeze-and-Excitation | Lecture 11 | Applied Deep Learning](https://www.youtube.com/watch?v=BSZqvObJVMg)  知乎也有一篇文章，不过讲解的不甚清晰  [深度残差网络(ResNet)论文学习(附代码实现)](https://zhuanlan.zhihu.com/p/70309480) 但是关于论文我还没有拜读

看了一些GAN的知识  参考的是[李宏毅老师 机器学习 2021spring](https://www.youtube.com/watch?v=4OWp0wDu6Xw)的课程



看一下学长发的19年最早的那篇语音伪造检测的文章

看一下ResNet怎么用到语音信号上？

学习一下语音信号的相关操作



如果觉得乱，可以去参考伍延珍老师的那篇综述看一下。



如果觉得无聊 可以去做实验 反正实验安排都出了 我觉得可以提前写完。。



Preprocess_SpeechToMel.py 将数据集转换为梅尔谱

数据集的写法

获得训练表单



在MultiDataset.py



语音路径|文件夹名

语音1|语音2|说话人



在MultiMel_DataSet类中指定*表单的输出位置*，*语音melspec的固定长度*，*训练集的 路径*

保存四个变量  训练 验证 测试 每个说话人的标签

每个说话人的标签中存放的格式是	说话人|标签

使用这个函数来定义这些变量make_scripts_of_normal_speechdataset

使用字典进行存储每个说话人的语音路径

通常训练集和验证集是交叉的，和测试集是不交叉的

调用p.parts把路径按照\隔开

所以字典是以每个说话人作为key，每个说话人的文件的列表作为值  A:[01,npy,02.npy]



筛选



切割验证集和测试集

N=2表示每个说话人要在（语音1|语音2|说话人）的表中出现两次，所以说要拿出4个语音

建立三个列表来遍历字典



可能会随着人数增加，测试和验证会花费时间太久，固定为50



speaker_list是一个列表，表示每一个说话人对应的下标



之后调用path_script_write写入的函数，创建三个文本文档的文件夹，进行写入



利用get_item方法读取每一个语音





模型的测试

model.py

pre是一个百分比的百分数

pred是一个概率的标签  必须给定真实的标签

OSISV模型 后端是AAM softmax进行打分









trainer的写法

说话人的分类数是要指定的，如果这个数字想要根据文件的个数动态的进行更改

说话人映射表的长度=说话人的数量

可以创建一个pic文件保存这个超参数



可以不写验证 写道另一个文件夹里？





模型的验证  OSISV

Evaluation_Test



SV_eval_or_test_function

mel12是mel1和mel2的拼凑



加载好模型和路径
